{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f7ffd75",
      "metadata": {
        "id": "4f7ffd75"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dcDrC9uPhcQ",
        "outputId": "e362b86b-6c46-4906-e0fc-7156eb8b3823"
      },
      "id": "1dcDrC9uPhcQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c5c4280",
      "metadata": {
        "id": "3c5c4280"
      },
      "outputs": [],
      "source": [
        "path_test = \"/content/drive/MyDrive/Image Classification Data/Images/Pet_Breeds\"\n",
        "category = ['abyssinian', 'american shorthair', 'beagle', 'boxer', 'bulldog', 'chihuahua', 'corgi', 'dachshund', 'german shepherd', 'golden retriever']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4b8bfc5",
      "metadata": {
        "id": "c4b8bfc5"
      },
      "outputs": [],
      "source": [
        "training = []\n",
        "def createTrainingData():\n",
        "    for cate in category:\n",
        "        path = os.path.join(path_test, cate)\n",
        "        class_num = category.index(cate)\n",
        "        for img in os.listdir(path):\n",
        "            img_array = cv2.imread(os.path.join(path, img))\n",
        "            new_array = cv2.resize(img_array, (200, 200))\n",
        "            training.append([new_array, class_num])\n",
        "createTrainingData()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aefad42",
      "metadata": {
        "id": "9aefad42",
        "outputId": "f4ab4865-7b81-4058-97e4-1a8994eece7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "training = np.array(training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b917ff60",
      "metadata": {
        "id": "b917ff60",
        "outputId": "c818d737-eba7-4061-b3c1-f70227dc42ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
              "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
              "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
              "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
              "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
              "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
              "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
              "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
              "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
              "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
              "       247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "np.unique(training[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29321c8",
      "metadata": {
        "id": "c29321c8"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(training[5][0])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51e83e61",
      "metadata": {
        "id": "51e83e61"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "for features, label in training:\n",
        "    X.append(features)\n",
        "    y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "392b344f",
      "metadata": {
        "id": "392b344f",
        "outputId": "25cdf411-aa52-446d-de1e-e84063df7816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.unique(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18f7e201",
      "metadata": {
        "id": "18f7e201"
      },
      "outputs": [],
      "source": [
        "X = np.array(X).reshape(-1, 200, 200, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947b83e1",
      "metadata": {
        "id": "947b83e1"
      },
      "outputs": [],
      "source": [
        "X = X.astype('float32')\n",
        "X = X/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33efbd72",
      "metadata": {
        "id": "33efbd72",
        "outputId": "6d3aafab-e358-4f97-a80c-7a99c034d012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(1700, 10)\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import np_utils\n",
        "Y = np_utils.to_categorical(y, 10)\n",
        "print(Y[100])\n",
        "print(Y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ca13fc5",
      "metadata": {
        "id": "3ca13fc5",
        "outputId": "a572e6ea-249d-4fc6-d9b5-636a7cb1f06c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "type(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3adaad6",
      "metadata": {
        "id": "e3adaad6"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45425fdf",
      "metadata": {
        "id": "45425fdf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb8f3cb7",
      "metadata": {
        "id": "fb8f3cb7",
        "outputId": "e0732af2-6a3a-4eda-8dda-d0e18d18c91d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1139, 200, 200, 3), (1139, 10), (561, 200, 200, 3), (561, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a43ba6",
      "metadata": {
        "id": "39a43ba6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25c6ae8f",
      "metadata": {
        "id": "25c6ae8f"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(128, (3,3), padding='same', activation='relu', input_shape=(200, 200, 3)),\n",
        "    MaxPooling2D((2,2), strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64, (3,3), padding='same', activation='relu'),\n",
        "    MaxPooling2D((2,2), strides=2),\n",
        "    BatchNormalization(),\n",
        " \n",
        "\n",
        "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    MaxPooling2D((2,2), strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "\n",
        "    Conv2D(16, (3,3), padding='same', activation='relu'),\n",
        "    MaxPooling2D((2,2), strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    \n",
        "    Conv2D(32, (3,3), padding='same', activation='relu'),\n",
        "    MaxPooling2D((2,2), strides=2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(64, (2,2), padding='same', activation='relu'),\n",
        "    MaxPooling2D((2,2), strides=2),\n",
        "    BatchNormalization(),\n",
        "    \n",
        "    Conv2D(128, (2,2), padding='same', activation='relu'),\n",
        "    MaxPooling2D((2,2), strides=2),\n",
        "    BatchNormalization(),\n",
        "    \n",
        "    Dropout(0.3),\n",
        "    Flatten(),\n",
        "    Dense(4, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da9ab366",
      "metadata": {
        "id": "da9ab366"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "574365d6",
      "metadata": {
        "id": "574365d6",
        "outputId": "6e859de6-0f87-421a-cad1-d3e9ecde0f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_18 (Conv2D)          (None, 200, 200, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 100, 100, 128)    0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 100, 100, 128)    512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 100, 100, 64)      73792     \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 50, 50, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 50, 50, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 50, 50, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 25, 25, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 25, 25, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 25, 25, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 12, 12, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 12, 12, 16)       64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 12, 12, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 6, 6, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_16 (Bat  (None, 6, 6, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 6, 6, 64)          8256      \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 3, 3, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 3, 3, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_24 (Conv2D)          (None, 3, 3, 128)         32896     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 1, 1, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 1, 1, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 1, 1, 128)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 516       \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148,678\n",
            "Trainable params: 147,750\n",
            "Non-trainable params: 928\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e344c5ed",
      "metadata": {
        "id": "e344c5ed",
        "outputId": "a61f0db4-90f9-43fc-818f-0a79d6d93b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.9715 - accuracy: 0.2757 - val_loss: 2.2028 - val_accuracy: 0.2299\n",
            "Epoch 2/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.9642 - accuracy: 0.2722 - val_loss: 2.1780 - val_accuracy: 0.2353\n",
            "Epoch 3/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.9369 - accuracy: 0.2959 - val_loss: 2.1912 - val_accuracy: 0.2299\n",
            "Epoch 4/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.9197 - accuracy: 0.2985 - val_loss: 2.1926 - val_accuracy: 0.2139\n",
            "Epoch 5/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.8953 - accuracy: 0.3011 - val_loss: 2.1770 - val_accuracy: 0.2371\n",
            "Epoch 6/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.9264 - accuracy: 0.2634 - val_loss: 2.2072 - val_accuracy: 0.2157\n",
            "Epoch 7/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.8807 - accuracy: 0.2932 - val_loss: 2.2033 - val_accuracy: 0.2299\n",
            "Epoch 8/1000\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 1.8770 - accuracy: 0.2915 - val_loss: 2.1973 - val_accuracy: 0.2406\n",
            "Epoch 9/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.8384 - accuracy: 0.3117 - val_loss: 2.1709 - val_accuracy: 0.2424\n",
            "Epoch 10/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.8246 - accuracy: 0.3126 - val_loss: 2.2314 - val_accuracy: 0.2103\n",
            "Epoch 11/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.7941 - accuracy: 0.3336 - val_loss: 2.2014 - val_accuracy: 0.1979\n",
            "Epoch 12/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.7630 - accuracy: 0.3178 - val_loss: 2.1974 - val_accuracy: 0.2157\n",
            "Epoch 13/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.8079 - accuracy: 0.3266 - val_loss: 2.1781 - val_accuracy: 0.2442\n",
            "Epoch 14/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.7597 - accuracy: 0.3389 - val_loss: 2.1712 - val_accuracy: 0.2353\n",
            "Epoch 15/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.7887 - accuracy: 0.3380 - val_loss: 2.1758 - val_accuracy: 0.2478\n",
            "Epoch 16/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.7415 - accuracy: 0.3565 - val_loss: 2.1724 - val_accuracy: 0.2282\n",
            "Epoch 17/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.7511 - accuracy: 0.3424 - val_loss: 2.2139 - val_accuracy: 0.2228\n",
            "Epoch 18/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.7301 - accuracy: 0.3371 - val_loss: 2.1694 - val_accuracy: 0.2656\n",
            "Epoch 19/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.6974 - accuracy: 0.3600 - val_loss: 2.1867 - val_accuracy: 0.2175\n",
            "Epoch 20/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.6609 - accuracy: 0.3661 - val_loss: 2.2493 - val_accuracy: 0.2299\n",
            "Epoch 21/1000\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 1.6615 - accuracy: 0.3723 - val_loss: 2.2793 - val_accuracy: 0.2050\n",
            "Epoch 22/1000\n",
            "36/36 [==============================] - 5s 126ms/step - loss: 1.6908 - accuracy: 0.3749 - val_loss: 2.2385 - val_accuracy: 0.2424\n",
            "Epoch 23/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.6545 - accuracy: 0.3696 - val_loss: 2.2290 - val_accuracy: 0.2442\n",
            "Epoch 24/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.6699 - accuracy: 0.3538 - val_loss: 2.1842 - val_accuracy: 0.2549\n",
            "Epoch 25/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.6332 - accuracy: 0.3740 - val_loss: 2.1780 - val_accuracy: 0.2478\n",
            "Epoch 26/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.6304 - accuracy: 0.3793 - val_loss: 2.2707 - val_accuracy: 0.2478\n",
            "Epoch 27/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.6064 - accuracy: 0.3889 - val_loss: 2.2310 - val_accuracy: 0.2496\n",
            "Epoch 28/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.6212 - accuracy: 0.3881 - val_loss: 2.2019 - val_accuracy: 0.2513\n",
            "Epoch 29/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.6076 - accuracy: 0.3863 - val_loss: 2.2549 - val_accuracy: 0.2585\n",
            "Epoch 30/1000\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 1.6047 - accuracy: 0.3977 - val_loss: 2.2061 - val_accuracy: 0.2424\n",
            "Epoch 31/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.6120 - accuracy: 0.3881 - val_loss: 2.1583 - val_accuracy: 0.2460\n",
            "Epoch 32/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.5490 - accuracy: 0.4100 - val_loss: 2.2114 - val_accuracy: 0.2602\n",
            "Epoch 33/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.5531 - accuracy: 0.4267 - val_loss: 2.2753 - val_accuracy: 0.2210\n",
            "Epoch 34/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.5783 - accuracy: 0.4030 - val_loss: 2.2334 - val_accuracy: 0.2567\n",
            "Epoch 35/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.5248 - accuracy: 0.4390 - val_loss: 2.2572 - val_accuracy: 0.2282\n",
            "Epoch 36/1000\n",
            "36/36 [==============================] - 4s 118ms/step - loss: 1.5283 - accuracy: 0.4179 - val_loss: 2.2027 - val_accuracy: 0.2264\n",
            "Epoch 37/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.5350 - accuracy: 0.4109 - val_loss: 2.2980 - val_accuracy: 0.2567\n",
            "Epoch 38/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.5357 - accuracy: 0.4205 - val_loss: 2.2572 - val_accuracy: 0.2371\n",
            "Epoch 39/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.5402 - accuracy: 0.4223 - val_loss: 2.2586 - val_accuracy: 0.2246\n",
            "Epoch 40/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.5045 - accuracy: 0.4276 - val_loss: 2.4069 - val_accuracy: 0.2389\n",
            "Epoch 41/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.5577 - accuracy: 0.3977 - val_loss: 2.3354 - val_accuracy: 0.2103\n",
            "Epoch 42/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4741 - accuracy: 0.4434 - val_loss: 2.2582 - val_accuracy: 0.2121\n",
            "Epoch 43/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4780 - accuracy: 0.4451 - val_loss: 2.2754 - val_accuracy: 0.2210\n",
            "Epoch 44/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4839 - accuracy: 0.4425 - val_loss: 2.2335 - val_accuracy: 0.2442\n",
            "Epoch 45/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4750 - accuracy: 0.4320 - val_loss: 2.3374 - val_accuracy: 0.2246\n",
            "Epoch 46/1000\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 1.4145 - accuracy: 0.4715 - val_loss: 2.3193 - val_accuracy: 0.2567\n",
            "Epoch 47/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4395 - accuracy: 0.4504 - val_loss: 2.3135 - val_accuracy: 0.2264\n",
            "Epoch 48/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4412 - accuracy: 0.4636 - val_loss: 2.2797 - val_accuracy: 0.2424\n",
            "Epoch 49/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4594 - accuracy: 0.4513 - val_loss: 2.3297 - val_accuracy: 0.2620\n",
            "Epoch 50/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4350 - accuracy: 0.4618 - val_loss: 2.2950 - val_accuracy: 0.2157\n",
            "Epoch 51/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4286 - accuracy: 0.4706 - val_loss: 2.3255 - val_accuracy: 0.2264\n",
            "Epoch 52/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4169 - accuracy: 0.4636 - val_loss: 2.3638 - val_accuracy: 0.2335\n",
            "Epoch 53/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3979 - accuracy: 0.4829 - val_loss: 2.3111 - val_accuracy: 0.2157\n",
            "Epoch 54/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3705 - accuracy: 0.4934 - val_loss: 2.2829 - val_accuracy: 0.2513\n",
            "Epoch 55/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3816 - accuracy: 0.4811 - val_loss: 2.3134 - val_accuracy: 0.2638\n",
            "Epoch 56/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4010 - accuracy: 0.4539 - val_loss: 2.2778 - val_accuracy: 0.2460\n",
            "Epoch 57/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.4140 - accuracy: 0.4557 - val_loss: 2.3295 - val_accuracy: 0.2478\n",
            "Epoch 58/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3775 - accuracy: 0.4785 - val_loss: 2.3664 - val_accuracy: 0.2781\n",
            "Epoch 59/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3446 - accuracy: 0.4899 - val_loss: 2.3668 - val_accuracy: 0.2406\n",
            "Epoch 60/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3772 - accuracy: 0.4706 - val_loss: 2.3523 - val_accuracy: 0.2531\n",
            "Epoch 61/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3819 - accuracy: 0.4802 - val_loss: 2.4149 - val_accuracy: 0.2406\n",
            "Epoch 62/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3451 - accuracy: 0.4680 - val_loss: 2.4819 - val_accuracy: 0.2139\n",
            "Epoch 63/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3360 - accuracy: 0.4864 - val_loss: 2.3589 - val_accuracy: 0.2460\n",
            "Epoch 64/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2796 - accuracy: 0.5338 - val_loss: 2.3627 - val_accuracy: 0.2353\n",
            "Epoch 65/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.3619 - accuracy: 0.4855 - val_loss: 2.5014 - val_accuracy: 0.2389\n",
            "Epoch 66/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3079 - accuracy: 0.5075 - val_loss: 2.3614 - val_accuracy: 0.2299\n",
            "Epoch 67/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3353 - accuracy: 0.4908 - val_loss: 2.4476 - val_accuracy: 0.2496\n",
            "Epoch 68/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.3566 - accuracy: 0.4829 - val_loss: 2.4344 - val_accuracy: 0.2228\n",
            "Epoch 69/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2561 - accuracy: 0.5162 - val_loss: 2.4251 - val_accuracy: 0.2317\n",
            "Epoch 70/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2974 - accuracy: 0.5189 - val_loss: 2.3991 - val_accuracy: 0.2299\n",
            "Epoch 71/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3089 - accuracy: 0.4873 - val_loss: 2.3845 - val_accuracy: 0.2389\n",
            "Epoch 72/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3150 - accuracy: 0.4881 - val_loss: 2.4959 - val_accuracy: 0.2246\n",
            "Epoch 73/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3535 - accuracy: 0.4767 - val_loss: 2.6266 - val_accuracy: 0.2246\n",
            "Epoch 74/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.3612 - accuracy: 0.4978 - val_loss: 2.4998 - val_accuracy: 0.2389\n",
            "Epoch 75/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.3102 - accuracy: 0.4969 - val_loss: 2.4472 - val_accuracy: 0.2353\n",
            "Epoch 76/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2811 - accuracy: 0.5075 - val_loss: 2.3850 - val_accuracy: 0.2246\n",
            "Epoch 77/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.3210 - accuracy: 0.4855 - val_loss: 2.5509 - val_accuracy: 0.2210\n",
            "Epoch 78/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2400 - accuracy: 0.5303 - val_loss: 2.4996 - val_accuracy: 0.2193\n",
            "Epoch 79/1000\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 1.2683 - accuracy: 0.5057 - val_loss: 2.5515 - val_accuracy: 0.2353\n",
            "Epoch 80/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.3072 - accuracy: 0.5101 - val_loss: 2.5493 - val_accuracy: 0.2424\n",
            "Epoch 81/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.3587 - accuracy: 0.4723 - val_loss: 2.5440 - val_accuracy: 0.2567\n",
            "Epoch 82/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2718 - accuracy: 0.5004 - val_loss: 2.5501 - val_accuracy: 0.2460\n",
            "Epoch 83/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2706 - accuracy: 0.5127 - val_loss: 2.4452 - val_accuracy: 0.2513\n",
            "Epoch 84/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2397 - accuracy: 0.5382 - val_loss: 2.4237 - val_accuracy: 0.2282\n",
            "Epoch 85/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2563 - accuracy: 0.5259 - val_loss: 2.4340 - val_accuracy: 0.2299\n",
            "Epoch 86/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2664 - accuracy: 0.4996 - val_loss: 2.4744 - val_accuracy: 0.2531\n",
            "Epoch 87/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2893 - accuracy: 0.5022 - val_loss: 2.4904 - val_accuracy: 0.2371\n",
            "Epoch 88/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2990 - accuracy: 0.5075 - val_loss: 2.5318 - val_accuracy: 0.2371\n",
            "Epoch 89/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2576 - accuracy: 0.5110 - val_loss: 2.5053 - val_accuracy: 0.2032\n",
            "Epoch 90/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2842 - accuracy: 0.4934 - val_loss: 2.6180 - val_accuracy: 0.2228\n",
            "Epoch 91/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2102 - accuracy: 0.5417 - val_loss: 2.5730 - val_accuracy: 0.2282\n",
            "Epoch 92/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2780 - accuracy: 0.5233 - val_loss: 2.5345 - val_accuracy: 0.2282\n",
            "Epoch 93/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2669 - accuracy: 0.5075 - val_loss: 2.5148 - val_accuracy: 0.2496\n",
            "Epoch 94/1000\n",
            "36/36 [==============================] - 5s 130ms/step - loss: 1.2615 - accuracy: 0.5031 - val_loss: 2.4595 - val_accuracy: 0.2193\n",
            "Epoch 95/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2435 - accuracy: 0.5259 - val_loss: 2.5336 - val_accuracy: 0.2478\n",
            "Epoch 96/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1982 - accuracy: 0.5356 - val_loss: 2.5429 - val_accuracy: 0.2317\n",
            "Epoch 97/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2019 - accuracy: 0.5364 - val_loss: 2.6279 - val_accuracy: 0.2424\n",
            "Epoch 98/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2339 - accuracy: 0.5312 - val_loss: 2.5177 - val_accuracy: 0.2799\n",
            "Epoch 99/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2542 - accuracy: 0.5154 - val_loss: 2.5780 - val_accuracy: 0.2442\n",
            "Epoch 100/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.2159 - accuracy: 0.5470 - val_loss: 2.5977 - val_accuracy: 0.2175\n",
            "Epoch 101/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1758 - accuracy: 0.5373 - val_loss: 2.5429 - val_accuracy: 0.2335\n",
            "Epoch 102/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1947 - accuracy: 0.5391 - val_loss: 2.6223 - val_accuracy: 0.2496\n",
            "Epoch 103/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1995 - accuracy: 0.5391 - val_loss: 2.6197 - val_accuracy: 0.2602\n",
            "Epoch 104/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1853 - accuracy: 0.5382 - val_loss: 2.5005 - val_accuracy: 0.2585\n",
            "Epoch 105/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1963 - accuracy: 0.5373 - val_loss: 2.6556 - val_accuracy: 0.2478\n",
            "Epoch 106/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.2210 - accuracy: 0.5294 - val_loss: 2.5984 - val_accuracy: 0.2513\n",
            "Epoch 107/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2277 - accuracy: 0.5338 - val_loss: 2.6093 - val_accuracy: 0.2299\n",
            "Epoch 108/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1851 - accuracy: 0.5285 - val_loss: 2.5644 - val_accuracy: 0.2567\n",
            "Epoch 109/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1995 - accuracy: 0.5338 - val_loss: 2.6690 - val_accuracy: 0.2531\n",
            "Epoch 110/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2200 - accuracy: 0.5233 - val_loss: 2.6613 - val_accuracy: 0.2442\n",
            "Epoch 111/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1693 - accuracy: 0.5514 - val_loss: 2.7383 - val_accuracy: 0.2335\n",
            "Epoch 112/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.1543 - accuracy: 0.5496 - val_loss: 2.6637 - val_accuracy: 0.2442\n",
            "Epoch 113/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.2145 - accuracy: 0.5303 - val_loss: 2.5768 - val_accuracy: 0.2602\n",
            "Epoch 114/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.2163 - accuracy: 0.5312 - val_loss: 2.5544 - val_accuracy: 0.2549\n",
            "Epoch 115/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1466 - accuracy: 0.5566 - val_loss: 2.5886 - val_accuracy: 0.2549\n",
            "Epoch 116/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.1864 - accuracy: 0.5443 - val_loss: 2.5848 - val_accuracy: 0.2531\n",
            "Epoch 117/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.1694 - accuracy: 0.5478 - val_loss: 2.5951 - val_accuracy: 0.2549\n",
            "Epoch 118/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1728 - accuracy: 0.5487 - val_loss: 2.7105 - val_accuracy: 0.2299\n",
            "Epoch 119/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1197 - accuracy: 0.5619 - val_loss: 2.6545 - val_accuracy: 0.2906\n",
            "Epoch 120/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1879 - accuracy: 0.5426 - val_loss: 2.5827 - val_accuracy: 0.2602\n",
            "Epoch 121/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.2087 - accuracy: 0.5259 - val_loss: 2.6142 - val_accuracy: 0.2424\n",
            "Epoch 122/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1810 - accuracy: 0.5452 - val_loss: 2.6623 - val_accuracy: 0.2531\n",
            "Epoch 123/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1456 - accuracy: 0.5522 - val_loss: 2.7202 - val_accuracy: 0.2353\n",
            "Epoch 124/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1740 - accuracy: 0.5496 - val_loss: 2.7973 - val_accuracy: 0.2371\n",
            "Epoch 125/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1657 - accuracy: 0.5461 - val_loss: 2.6192 - val_accuracy: 0.2567\n",
            "Epoch 126/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1955 - accuracy: 0.5408 - val_loss: 3.1280 - val_accuracy: 0.2246\n",
            "Epoch 127/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1850 - accuracy: 0.5338 - val_loss: 2.6602 - val_accuracy: 0.2299\n",
            "Epoch 128/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1605 - accuracy: 0.5373 - val_loss: 2.6495 - val_accuracy: 0.2424\n",
            "Epoch 129/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1828 - accuracy: 0.5347 - val_loss: 2.7845 - val_accuracy: 0.2353\n",
            "Epoch 130/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1688 - accuracy: 0.5470 - val_loss: 2.7296 - val_accuracy: 0.2460\n",
            "Epoch 131/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1868 - accuracy: 0.5356 - val_loss: 2.7615 - val_accuracy: 0.2478\n",
            "Epoch 132/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1763 - accuracy: 0.5408 - val_loss: 2.7203 - val_accuracy: 0.2692\n",
            "Epoch 133/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1421 - accuracy: 0.5522 - val_loss: 3.1054 - val_accuracy: 0.2317\n",
            "Epoch 134/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1769 - accuracy: 0.5373 - val_loss: 2.7357 - val_accuracy: 0.2424\n",
            "Epoch 135/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1161 - accuracy: 0.5654 - val_loss: 2.7237 - val_accuracy: 0.2478\n",
            "Epoch 136/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1698 - accuracy: 0.5522 - val_loss: 2.7150 - val_accuracy: 0.2175\n",
            "Epoch 137/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1033 - accuracy: 0.5593 - val_loss: 2.8501 - val_accuracy: 0.2424\n",
            "Epoch 138/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1434 - accuracy: 0.5558 - val_loss: 2.6411 - val_accuracy: 0.2460\n",
            "Epoch 139/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0981 - accuracy: 0.5891 - val_loss: 2.7513 - val_accuracy: 0.2424\n",
            "Epoch 140/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.0689 - accuracy: 0.5874 - val_loss: 2.6796 - val_accuracy: 0.2335\n",
            "Epoch 141/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1567 - accuracy: 0.5505 - val_loss: 2.7108 - val_accuracy: 0.2424\n",
            "Epoch 142/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1339 - accuracy: 0.5478 - val_loss: 2.7212 - val_accuracy: 0.2442\n",
            "Epoch 143/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1252 - accuracy: 0.5637 - val_loss: 2.7648 - val_accuracy: 0.2513\n",
            "Epoch 144/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.1477 - accuracy: 0.5435 - val_loss: 2.7974 - val_accuracy: 0.2496\n",
            "Epoch 145/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1194 - accuracy: 0.5689 - val_loss: 2.8070 - val_accuracy: 0.2335\n",
            "Epoch 146/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1142 - accuracy: 0.5654 - val_loss: 2.6862 - val_accuracy: 0.2460\n",
            "Epoch 147/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1672 - accuracy: 0.5391 - val_loss: 2.6595 - val_accuracy: 0.2353\n",
            "Epoch 148/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1278 - accuracy: 0.5558 - val_loss: 2.7602 - val_accuracy: 0.2282\n",
            "Epoch 149/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.1567 - accuracy: 0.5443 - val_loss: 2.6586 - val_accuracy: 0.2442\n",
            "Epoch 150/1000\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 1.1640 - accuracy: 0.5584 - val_loss: 3.2935 - val_accuracy: 0.2335\n",
            "Epoch 151/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1919 - accuracy: 0.5356 - val_loss: 2.8559 - val_accuracy: 0.2139\n",
            "Epoch 152/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0973 - accuracy: 0.5812 - val_loss: 2.7408 - val_accuracy: 0.2335\n",
            "Epoch 153/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0923 - accuracy: 0.5698 - val_loss: 2.6785 - val_accuracy: 0.2478\n",
            "Epoch 154/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.1344 - accuracy: 0.5645 - val_loss: 2.7985 - val_accuracy: 0.2531\n",
            "Epoch 155/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0794 - accuracy: 0.5882 - val_loss: 2.7120 - val_accuracy: 0.2585\n",
            "Epoch 156/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.0921 - accuracy: 0.5733 - val_loss: 2.8166 - val_accuracy: 0.2567\n",
            "Epoch 157/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1545 - accuracy: 0.5496 - val_loss: 2.8423 - val_accuracy: 0.2442\n",
            "Epoch 158/1000\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 1.1073 - accuracy: 0.5672 - val_loss: 2.7271 - val_accuracy: 0.2531\n",
            "Epoch 159/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0950 - accuracy: 0.5672 - val_loss: 2.7889 - val_accuracy: 0.2317\n",
            "Epoch 160/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0899 - accuracy: 0.5803 - val_loss: 2.7695 - val_accuracy: 0.2620\n",
            "Epoch 161/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0483 - accuracy: 0.6014 - val_loss: 2.8235 - val_accuracy: 0.2567\n",
            "Epoch 162/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0889 - accuracy: 0.5900 - val_loss: 2.8043 - val_accuracy: 0.2442\n",
            "Epoch 163/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1499 - accuracy: 0.5593 - val_loss: 2.8196 - val_accuracy: 0.2299\n",
            "Epoch 164/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1075 - accuracy: 0.5803 - val_loss: 2.7881 - val_accuracy: 0.2531\n",
            "Epoch 165/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1359 - accuracy: 0.5654 - val_loss: 2.8463 - val_accuracy: 0.2567\n",
            "Epoch 166/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1483 - accuracy: 0.5470 - val_loss: 2.8219 - val_accuracy: 0.2602\n",
            "Epoch 167/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1199 - accuracy: 0.5619 - val_loss: 2.7613 - val_accuracy: 0.2620\n",
            "Epoch 168/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0747 - accuracy: 0.5821 - val_loss: 2.7714 - val_accuracy: 0.2496\n",
            "Epoch 169/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0999 - accuracy: 0.5672 - val_loss: 2.8498 - val_accuracy: 0.2567\n",
            "Epoch 170/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.1404 - accuracy: 0.5531 - val_loss: 2.9498 - val_accuracy: 0.2264\n",
            "Epoch 171/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1268 - accuracy: 0.5645 - val_loss: 2.9091 - val_accuracy: 0.2210\n",
            "Epoch 172/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0665 - accuracy: 0.5909 - val_loss: 2.8263 - val_accuracy: 0.2210\n",
            "Epoch 173/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1251 - accuracy: 0.5566 - val_loss: 2.8497 - val_accuracy: 0.2193\n",
            "Epoch 174/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1068 - accuracy: 0.5698 - val_loss: 2.9287 - val_accuracy: 0.2264\n",
            "Epoch 175/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1104 - accuracy: 0.5698 - val_loss: 2.8786 - val_accuracy: 0.2299\n",
            "Epoch 176/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1009 - accuracy: 0.5698 - val_loss: 2.7637 - val_accuracy: 0.2674\n",
            "Epoch 177/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1511 - accuracy: 0.5426 - val_loss: 3.0059 - val_accuracy: 0.2246\n",
            "Epoch 178/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1583 - accuracy: 0.5584 - val_loss: 2.8764 - val_accuracy: 0.2460\n",
            "Epoch 179/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.0737 - accuracy: 0.5830 - val_loss: 2.9112 - val_accuracy: 0.2282\n",
            "Epoch 180/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1354 - accuracy: 0.5522 - val_loss: 2.8179 - val_accuracy: 0.2371\n",
            "Epoch 181/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1132 - accuracy: 0.5549 - val_loss: 2.9825 - val_accuracy: 0.2549\n",
            "Epoch 182/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.1049 - accuracy: 0.5663 - val_loss: 2.8435 - val_accuracy: 0.2389\n",
            "Epoch 183/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1301 - accuracy: 0.5637 - val_loss: 2.9497 - val_accuracy: 0.2406\n",
            "Epoch 184/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1047 - accuracy: 0.5672 - val_loss: 2.9166 - val_accuracy: 0.2406\n",
            "Epoch 185/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1531 - accuracy: 0.5364 - val_loss: 2.9542 - val_accuracy: 0.2460\n",
            "Epoch 186/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.0490 - accuracy: 0.5900 - val_loss: 2.8016 - val_accuracy: 0.2585\n",
            "Epoch 187/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0904 - accuracy: 0.5751 - val_loss: 2.8733 - val_accuracy: 0.2478\n",
            "Epoch 188/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0860 - accuracy: 0.5680 - val_loss: 2.9382 - val_accuracy: 0.2531\n",
            "Epoch 189/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0893 - accuracy: 0.5882 - val_loss: 2.8898 - val_accuracy: 0.2602\n",
            "Epoch 190/1000\n",
            "36/36 [==============================] - 4s 119ms/step - loss: 1.0985 - accuracy: 0.5768 - val_loss: 2.8431 - val_accuracy: 0.2513\n",
            "Epoch 191/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0602 - accuracy: 0.5847 - val_loss: 2.8651 - val_accuracy: 0.2460\n",
            "Epoch 192/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0930 - accuracy: 0.5742 - val_loss: 2.9028 - val_accuracy: 0.2585\n",
            "Epoch 193/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.0933 - accuracy: 0.5680 - val_loss: 2.8968 - val_accuracy: 0.2549\n",
            "Epoch 194/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.1043 - accuracy: 0.5645 - val_loss: 2.9078 - val_accuracy: 0.2567\n",
            "Epoch 195/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0928 - accuracy: 0.5672 - val_loss: 2.8809 - val_accuracy: 0.2567\n",
            "Epoch 196/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0875 - accuracy: 0.5698 - val_loss: 2.9403 - val_accuracy: 0.2424\n",
            "Epoch 197/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0914 - accuracy: 0.5716 - val_loss: 2.9496 - val_accuracy: 0.2406\n",
            "Epoch 198/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0971 - accuracy: 0.5663 - val_loss: 2.9842 - val_accuracy: 0.2299\n",
            "Epoch 199/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0884 - accuracy: 0.5724 - val_loss: 2.9073 - val_accuracy: 0.2406\n",
            "Epoch 200/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0826 - accuracy: 0.5733 - val_loss: 3.1021 - val_accuracy: 0.2389\n",
            "Epoch 201/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.1076 - accuracy: 0.5637 - val_loss: 3.2874 - val_accuracy: 0.2228\n",
            "Epoch 202/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1169 - accuracy: 0.5610 - val_loss: 2.9312 - val_accuracy: 0.2816\n",
            "Epoch 203/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.1565 - accuracy: 0.5558 - val_loss: 3.5502 - val_accuracy: 0.2103\n",
            "Epoch 204/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.1102 - accuracy: 0.5795 - val_loss: 2.8863 - val_accuracy: 0.2424\n",
            "Epoch 205/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0650 - accuracy: 0.5847 - val_loss: 2.8397 - val_accuracy: 0.2567\n",
            "Epoch 206/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0768 - accuracy: 0.5821 - val_loss: 2.9455 - val_accuracy: 0.2406\n",
            "Epoch 207/1000\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 1.1151 - accuracy: 0.5680 - val_loss: 2.8971 - val_accuracy: 0.2460\n",
            "Epoch 208/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1106 - accuracy: 0.5558 - val_loss: 2.9021 - val_accuracy: 0.2638\n",
            "Epoch 209/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0765 - accuracy: 0.5751 - val_loss: 3.0317 - val_accuracy: 0.2460\n",
            "Epoch 210/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0815 - accuracy: 0.5663 - val_loss: 3.1190 - val_accuracy: 0.2228\n",
            "Epoch 211/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0980 - accuracy: 0.5672 - val_loss: 2.9733 - val_accuracy: 0.2460\n",
            "Epoch 212/1000\n",
            "36/36 [==============================] - 4s 122ms/step - loss: 1.0989 - accuracy: 0.5654 - val_loss: 2.9756 - val_accuracy: 0.2549\n",
            "Epoch 213/1000\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 1.0503 - accuracy: 0.5874 - val_loss: 2.9656 - val_accuracy: 0.2335\n",
            "Epoch 214/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0256 - accuracy: 0.5900 - val_loss: 3.0496 - val_accuracy: 0.2531\n",
            "Epoch 215/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0465 - accuracy: 0.5909 - val_loss: 3.0145 - val_accuracy: 0.2371\n",
            "Epoch 216/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0489 - accuracy: 0.5874 - val_loss: 3.0128 - val_accuracy: 0.2496\n",
            "Epoch 217/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0509 - accuracy: 0.5874 - val_loss: 3.1030 - val_accuracy: 0.2585\n",
            "Epoch 218/1000\n",
            "36/36 [==============================] - 4s 123ms/step - loss: 1.0593 - accuracy: 0.5891 - val_loss: 3.0117 - val_accuracy: 0.2656\n",
            "Epoch 219/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0838 - accuracy: 0.5751 - val_loss: 3.1335 - val_accuracy: 0.2335\n",
            "Epoch 220/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.1230 - accuracy: 0.5584 - val_loss: 3.0290 - val_accuracy: 0.2406\n",
            "Epoch 221/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0939 - accuracy: 0.5689 - val_loss: 2.9755 - val_accuracy: 0.2371\n",
            "Epoch 222/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1043 - accuracy: 0.5593 - val_loss: 2.9967 - val_accuracy: 0.2478\n",
            "Epoch 223/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0942 - accuracy: 0.5716 - val_loss: 3.1055 - val_accuracy: 0.2282\n",
            "Epoch 224/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0382 - accuracy: 0.5953 - val_loss: 3.0846 - val_accuracy: 0.2513\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0893 - accuracy: 0.5680 - val_loss: 3.0546 - val_accuracy: 0.2585\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0725 - accuracy: 0.5707 - val_loss: 2.9610 - val_accuracy: 0.2656\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 4s 124ms/step - loss: 1.0835 - accuracy: 0.5751 - val_loss: 2.9897 - val_accuracy: 0.2656\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0611 - accuracy: 0.5847 - val_loss: 3.0576 - val_accuracy: 0.2424\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0920 - accuracy: 0.5637 - val_loss: 2.9586 - val_accuracy: 0.2549\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.1065 - accuracy: 0.5610 - val_loss: 2.9983 - val_accuracy: 0.2692\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0611 - accuracy: 0.5716 - val_loss: 3.0171 - val_accuracy: 0.2442\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0074 - accuracy: 0.6040 - val_loss: 3.0626 - val_accuracy: 0.2389\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.1011 - accuracy: 0.5584 - val_loss: 3.0923 - val_accuracy: 0.2656\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0045 - accuracy: 0.6119 - val_loss: 3.0021 - val_accuracy: 0.2371\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0637 - accuracy: 0.5751 - val_loss: 3.0200 - val_accuracy: 0.2496\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0697 - accuracy: 0.5821 - val_loss: 2.8957 - val_accuracy: 0.2674\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0330 - accuracy: 0.5926 - val_loss: 2.9379 - val_accuracy: 0.2406\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 1.0498 - accuracy: 0.5900 - val_loss: 3.0222 - val_accuracy: 0.2460\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 4s 120ms/step - loss: 1.0727 - accuracy: 0.5707 - val_loss: 3.0744 - val_accuracy: 0.2513\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 4s 121ms/step - loss: 0.9880 - accuracy: 0.6076 - val_loss: 2.9891 - val_accuracy: 0.2406\n",
            "Epoch 241/1000\n",
            "20/36 [===============>..............] - ETA: 1s - loss: 1.0461 - accuracy: 0.5797"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-b8e0128a0e61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train, epochs=1000, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf59c61",
      "metadata": {
        "id": "adf59c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "eb30d8e0-514e-4957-b69b-d14749a59d25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3iUVfbA8e9JTyAECKH33mtAEARURIoiioIFxYpl3XV1ddXfuq5r2bX3VUFEFJAiiiIgUgQstARCDR1CEgIhEBJKeub+/ngnOIRAJslMZpKcz/PMw8xbzyDm5N7z3nvFGINSSinlLB9PB6CUUqpi0cShlFKqRDRxKKWUKhFNHEoppUpEE4dSSqkS0cShlFKqRDRxKHUJIjJNRF528tg4ERni7piU8jRNHEoppUpEE4dSVYCI+Hk6BlV5aOJQFZ69i+gpEdkqImdF5DMRqSciP4rIaRFZLiK1HI4fJSI7RCRNRFaJSAeHfT1EZJP9vDlAUKF7XScim+3nrhGRrk7GOFJEYkTklIgkiMgLhfYPsF8vzb7/bvv2YBF5S0QOiUi6iPxm3zZYRBKL+HsYYn//gojME5EZInIKuFtE+ojIWvs9jojIhyIS4HB+JxFZJiKpIpIsIv8nIvVFJENEwh2O6ykiKSLi78x3V5WPJg5VWYwBrgHaAtcDPwL/B0Rg/Tv/C4CItAVmAX+171sM/CAiAfYfot8B04HawNf262I/twcwFXgQCAcmAQtEJNCJ+M4CdwE1gZHAwyIy2n7dZvZ4P7DH1B3YbD/vTaAXcLk9pr8DNif/Tm4A5tnvORPIBx4H6gD9gKuBR+wxhALLgSVAQ6A1sMIYcxRYBYx1uO6dwGxjTK6TcahKRhOHqiw+MMYkG2MOA78C640xMcaYLGA+0MN+3DhgkTFmmf0H35tAMNYP5r6AP/CuMSbXGDMPiHK4x0RgkjFmvTEm3xjzBZBtP++SjDGrjDHbjDE2Y8xWrOQ1yL77dmC5MWaW/b4njDGbRcQHuBd4zBhz2H7PNcaYbCf/TtYaY76z3zPTGLPRGLPOGJNnjInDSnwFMVwHHDXGvGWMyTLGnDbGrLfv+wIYDyAivsBtWMlVVVGaOFRlkezwPrOIz9Xt7xsChwp2GGNsQALQyL7vsDl/5s9DDu+bAX+zd/WkiUga0MR+3iWJyGUistLexZMOPIT1mz/2a+wv4rQ6WF1lRe1zRkKhGNqKyEIROWrvvvqPEzEAfA90FJEWWK26dGPMhlLGpCoBTRyqqknCSgAAiIhg/dA8DBwBGtm3FWjq8D4BeMUYU9PhFWKMmeXEfb8CFgBNjDFhwCdAwX0SgFZFnHMcyLrIvrNAiMP38MXq5nJUeOrrj4FdQBtjTA2srjzHGFoWFbi91TYXq9VxJ9raqPI0caiqZi4wUkSuthd3/4bV3bQGWAvkAX8REX8RuQno43Dup8BD9taDiEg1e9E71In7hgKpxpgsEemD1T1VYCYwRETGioifiISLSHd7a2gq8LaINBQRXxHpZ6+p7AGC7Pf3B54Diqu1hAKngDMi0h542GHfQqCBiPxVRAJFJFRELnPY/yVwNzAKTRxVniYOVaUYY3Zj/eb8AdZv9NcD1xtjcowxOcBNWD8gU7HqId86nBsNPAB8CJwE9tmPdcYjwIsichp4HiuBFVw3HhiBlcRSsQrj3ey7nwS2YdVaUoHXAB9jTLr9mlOwWktngfOesirCk1gJ6zRWEpzjEMNprG6o64GjwF7gSof9v2MV5TcZYxy771QVJLqQk1LKGSLyM/CVMWaKp2NRnqWJQylVLBHpDSzDqtGc9nQ8yrO0q0opdUki8gXWGI+/atJQoC0OpZRSJaQtDqWUUiVSJSY+q1OnjmnevLmnw1BKqQpl48aNx40xhccHVY3E0bx5c6Kjoz0dhlJKVSgiUuSj19pVpZRSqkQ0cSillCoRtyYOERkmIrtFZJ+IPFPE/idEJFasdRRW2KeXRkSutK95UPDKcpiCepqIHHTY192d30EppdT53FbjsE+69j+saQwSgSgRWWCMiXU4LAaINMZkiMjDwOvAOGPMSqw1CRCR2lhTOyx1OO8p+5TXpZabm0tiYiJZWVlluYzXCwoKonHjxvj765o7SinXcGdxvA+wzxhzAEBEZmMtLHMucdgTRIF12Of8L+Rm4EdjTIYrg0tMTCQ0NJTmzZtz/mSolYcxhhMnTpCYmEiLFi08HY5SqpJwZ1dVI85fDyDRvu1i7sNaBa2wW7EWvXH0ir17652Lrb4mIhNFJFpEolNSUi7Yn5WVRXh4eKVNGgAiQnh4eKVvVSmlypdXFMdFZDwQCbxRaHsDoAvwk8PmZ4H2QG+spTSfLuqaxpjJxphIY0xkRMQFjyEXXL/swXu5qvAdlVLly52J4zDWAjkFGtu3nUdEhgD/AEYVsSTmWGC+49rGxpgjxpINfM756yUopZQCkk9l8Z/FOzl+xtmVhp3nzsQRBbQRkRYiEoDV5bTA8QAR6YG17vEoY8yxIq5xG4W6qeytkIKV20YD290Qu9ulpaXx0Ucflfi8ESNGkJaW5oaIlFKVyZRfD/DZbwfJyM53+bXdljiMMXnAo1jdTDuBucaYHSLyooiMsh/2BtZa0F/bH609l1hEpDlWi2V1oUvPFJFtWIvb1AFedtd3cKeLJY68vLxLnrd48WJq1qzprrCUUpVAWkYOM9fHc33XBjQNDyn+hBJy65QjxpjFwOJC2553eD/kEufGUUQx3RhzlQtD9JhnnnmG/fv30717d/z9/QkKCqJWrVrs2rWLPXv2MHr0aBISEsjKyuKxxx5j4sSJwB/Tp5w5c4bhw4czYMAA1qxZQ6NGjfj+++8JDg728DdTSnnatDVxZOTk8/Dg1m65fpWYq6o4//5hB7FJp1x6zY4Na/Cv6ztddP+rr77K9u3b2bx5M6tWrWLkyJFs37793GOzU6dOpXbt2mRmZtK7d2/GjBlDeHj4edfYu3cvs2bN4tNPP2Xs2LF88803jB9f1BPNSqmq4mx2HtPWxDGkQz3a1Q91yz00cXiJPn36nDfW4v3332f+/PkAJCQksHfv3gsSR4sWLeje3Ro436tXL+Li4sotXqWUd5q1IZ60jFweubKV2+6hiQMu2TIoL9WqVTv3ftWqVSxfvpy1a9cSEhLC4MGDixyLERj4xxAWX19fMjMzyyVWpZR3ys7L59NfD9C3ZW16Nq3ltvt4xTiOqig0NJTTp4tehTM9PZ1atWoREhLCrl27WLduXTlHp5SqiOZvOkzyqWwecVNto4C2ODwkPDyc/v3707lzZ4KDg6lXr965fcOGDeOTTz6hQ4cOtGvXjr59+3owUqVURZBvM3yyej9dGoVxRZs6br2XJg4P+uqrr4rcHhgYyI8/FjX7CufqGHXq1GH79j+GsDz55JMuj08pVXEs3naEuBMZfHxHT7fPGKFdVUopVcEZY/ho1X5aRlTj2k713X4/TRxKKVXBrdqTws4jp3h4UCt8fNw/P50mDqWUquA+XrmfhmFB3ND9UhOQu44mDqWUqsCi4lLZEJfKAwNbEuBXPj/SNXEopVQF9tHKfdSuFsCtvZuW2z01cSilVAW1IymdlbtTuLd/c4IDfMvtvpo4PKS006oDvPvuu2RkuHQlXaVUBfTxqv1UD/Tjzn7Ny/W+mjg8RBOHUqos4o6fZfG2I4zv24ywYP9yvbcOAPQQx2nVr7nmGurWrcvcuXPJzs7mxhtv5N///jdnz55l7NixJCYmkp+fzz//+U+Sk5NJSkriyiuvpE6dOqxcudLTX0Up5QGTftmPn68P9w5oXu731sQB8OMzcHSba69ZvwsMf/Wiux2nVV+6dCnz5s1jw4YNGGMYNWoUv/zyCykpKTRs2JBFixYB1hxWYWFhvP3226xcuZI6ddw7rYBSyjsdTc9i3sZExvVuQt3QoHK/v3ZVeYGlS5eydOlSevToQc+ePdm1axd79+6lS5cuLFu2jKeffppff/2VsLAwT4eqlPICU349gM3AgwPdN3X6pWiLAy7ZMigPxhieffZZHnzwwQv2bdq0icWLF/Pcc89x9dVX8/zzzxdxBaVUVXHybA5fbYhnVLeGNKnt+mVhneHWFoeIDBOR3SKyT0SeKWL/EyISKyJbRWSFiDRz2JdvX4e88FrkLURkvf2ac0QkwJ3fwV0cp1W/9tprmTp1KmfOnAHg8OHDHDt2jKSkJEJCQhg/fjxPPfUUmzZtuuBcpVTV8seysJ5pbYAbWxwi4gv8D7gGSASiRGSBMSbW4bAYINIYkyEiDwOvA+Ps+zKNMd2LuPRrwDvGmNki8glwH/Cxu76HuzhOqz58+HBuv/12+vXrB0D16tWZMWMG+/bt46mnnsLHxwd/f38+/tj6mhMnTmTYsGE0bNhQi+NKVSGOy8K2reeeZWGdIcYY91xYpB/wgjHmWvvnZwGMMf+9yPE9gA+NMf3tn88YY6oXOkaAFKC+MSav8D0uJjIy0kRHR5+3befOnXTo0KF0X66CqUrfVanKbMqvB3h50U6+feRyt67wV0BENhpjIgtvd2dXVSMgweFzon3bxdwHOC5CESQi0SKyTkRG27eFA2nGmLzirikiE+3nR6ekpJTuGyillJcoWBa2X8vwckkal+IVxXERGQ9EAoMcNjczxhwWkZbAzyKyDUh39prGmMnAZLBaHK6MVymlytu39mVh37ylm6dDcWuL4zDQxOFzY/u284jIEOAfwChjTHbBdmPMYfufB4BVQA/gBFBTRAoSXpHXdJa7uum8SVX4jkp5o9NZuWxLTMdmK/v/g3n5Nj5ZvZ+ujcMY0Nrz47fc2eKIAtqISAusH+63Arc7HmCva0wChhljjjlsrwVkGGOyRaQO0B943RhjRGQlcDMwG5gAfF+a4IKCgjhx4gTh4eFuX2bRU4wxnDhxgqCg8h8gpFRVlJWbz6rdKSzYcpgVO4+RnWejSe1gbu/TjLGRjQmvHliq6y7efpRDJzL4ZLz7l4V1htuK4wAiMgJ4F/AFphpjXhGRF4FoY8wCEVkOdAGO2E+JN8aMEpHLsRKKDatV9K4x5jP7NVtiJY3aWE9ljXdsqRSlqOJ4bm4uiYmJZGVluerreqWgoCAaN26Mv3/5zmWjVFmdzc5jS2Ial7fy/G/Yl5JvM6w/cILvNh/mx+1HOZ2VR3i1AK7r2oCODWvw7abDrD+YSoCvD8O71Gd832ZENqvldAIwxjDi/d/Iyctn2eODymWFvwIXK467NXF4i6ISh1LKuz0+ZzPzYw7zwvUdubt/C0+Hcx5jDNsOp/P95iR+2JLEsdPZVAvw5drO9bmheyP6twrHz/ePSsDe5NPMXB/PNxsTOZ2dR/v6odxxWVNG92hEaNClf6lbuesY90yL4s1bunFzr8bu/mrn0cShiUOpCiMm/iQ3frSG2tUCSMvI4bMJvbmyfV1Ph8WBlDN8vzmJBVuSOHj8LAG+PgxuF8EN3RtxdYe6BPlfek2MjJw8vt+cxIx1h9iRdIpqAb7c0KMR4y9rRseGNYo85+aP13AkPYtVTw3G37d8Z4nSxKGJQ6kKwRjDmI/XkHAyk0V/GcA9n0cRd/wsXz90+UV/uLrT0fQsFm5N4vvNSWw7nI4IXN4qnFHdGjKsUwPCQkreDWyMYXNCGjPWxbNwaxLZeTZ6Nq3J+L7NGNGlwbkEtOFgKmMnrfVYq0sThyYOpSqEBVuS+MusGF4f05WxvZtwND2L0f/7HRH4/k/9qVujfB72iE06xUsLY1l38ATGQLfGYYzq3ojrujagngtjSMvIYd7GRGauj+fg8bPUCvHnlsgm3HFZU/61YAfbEtP57emrynWFvwKaODRxKOX1snLzuerNVdSqFsCCRwfgay8E70hK55ZP1tIqojpzHuxLSIB7h6BFx6Vyz7Qogv19uf2ypozq1pCWEdWLP7EMbDbDmv0nmLHuEMt2JpNvf4z3qWvb8acrW7v13hdzscThFQMAlVIKrCk1ktKzeHtc93NJA6BTwzA+uK0HD3wZzeNzNvPxHb3c9nTR6j0pPDg9moZhwcy4/zIa1gx2y30K8/ERBrSpw4A2dTiansXsqHi2Hz7Fnf2aFX9yOdP1OJRSXiH5VBYfrdrPsE716dsy/IL9V3eox3MjO/LTjmReW7LLLTEs3naE+7+IomWd6sx9qF+5JY3C6ocF8dchbZkyIZIaxTx15Qna4lBKeYU3f9pNXr7h2RHtL3rMPf2bc/D4WSb9coDmdapxW5+mLrv/3KgEnvl2Kz2b1uKzu3uX+zreFYkmDqWUx21LTGfepkQmXtGSZuHVLnqciPCv6zsSn5rBc99tp0mtEAa0KfsAwc9+O8hLC2O5ok0dJt3Zy+01lIpOu6qUUh5ljOGlhbHUDgngT1cVXwT28/Xhw9t70DqiOg/P3Mje5NIvamaM4Z1le3hpYSzDO9dnyoRITRpO0MShlPKoJduPsiEulSeGtnW6Pz80yJ/P7o4k0M+Xe6ZFcfzMJWcdKpLNZnhxYSzvrdjLLb0a88FtPQj0K/9HXisiTRxKKY/Jys3nPz/upH39UMZFNin+BAeNa4Xw2YRIjp/J5oEvo8nKzXf63Lx8G3//Ziuf/x7Hvf1b8NqYrudNEaIuTf+mlFIeM21NHAmpmTw3smOpfnB3a1KTd8Z2JyY+jSe/3uLUFObZefk8+lUM8zYm8viQtvzzug7lOnFgZaCJQynlESmns/nw530M6VC3TAXu4V0a8PSw9izceoR3lu+55LEZOXnc/0U0S3Yc5fnrOvLYkDZeMU15RaNVIKWUR7y9bDdZufn834gOZb7WQ4NaEnf8LB/8vI/m4dUYU8QssumZudw7LYqY+JO8fnNXxpawa0z9QROHUqrcxSadYk5UAndf3sIlU3mICC/f2JmEkxk88+1WGtUKPm8QYcrpbO6auoF9x07zv9t7MrxLgzLfsyrTriqlVLkyxvDyolhqBPvz2NVtXHZdf18fPr6jF01rh/Dg9I0cSDkDwOG0TMZOWsvB42eYMqG3Jg0X0MShlCpXy3ceY83+Ezw+pG2ppiS/lLAQf6be3RtfH+G+L6LZeOgkt3y8huNnsplx32UMahvh0vt5tdPJ8OtbkJHq8ktr4lBKlZucPBuvLIqlVUQ1br/MddOFOGoWXo3Jd/bi8MlMxny8huw8G7Mn9iWyeW233M9rbfoCVrwImSddfmm3Jg4RGSYiu0Vkn4g8U8T+J0QkVkS2isgKEWlm395dRNaKyA77vnEO50wTkYMistn+6u7O76CUcp0v18YRdyKD567r6NbV7CKb1+bdW7sT2awWcx/qR6eGYW67l1fKz4XoqdDqaghv5fLLu604LiK+wP+Aa4BEIEpEFhhjYh0OiwEijTEZIvIw8DowDsgA7jLG7BWRhsBGEfnJGJNmP+8pY8w8d8WulHK91LM5vLdiLwPbRnBlO/cvAzuiSwNGVNV6xq5FcPoIXPeOWy7vzhZHH2CfMeaAMSYHmA3c4HiAMWalMSbD/nEd0Ni+fY8xZq/9fRJwDKhCnZNKVT7vLNtDRk4+z40s++O3qhgbPoWaTaHNULdc3p2JoxGQ4PA50b7tYu4Dfiy8UUT6AAHAfofNr9i7sN4RkcCiLiYiE0UkWkSiU1JSSh69Uspl9iSf5qsN8dxxWVPa1gv1dDiVW3IsHPoNIu8DH/fMveUVxXERGQ9EAm8U2t4AmA7cY4yx2Tc/C7QHegO1gaeLuqYxZrIxJtIYExkRoY0VpTzp5UU7CQnw5a9D2no6lPKTHAuL/w65meV736hPwS8Iet7ltlu4M3EcBhyHZja2bzuPiAwB/gGMMsZkO2yvASwC/mGMWVew3RhzxFiygc+xusSUUl5q5e5j/LInhceubkPtagGeDqd85GTA3LtgwySI/rz87puVDlvmQOebIcR9T5G5M3FEAW1EpIWIBAC3AgscDxCRHsAkrKRxzGF7ADAf+LJwEdzeCkGsCWZGA9vd+B2UUmWQm2/j5YWxtKhTjbv6Nfd0OOVn2T/hxF6o3RJ+f7f8Wh2bZ0HuWehzv1tv47bEYYzJAx4FfgJ2AnONMTtE5EURGWU/7A2gOvC1/dHagsQyFhgI3F3EY7czRWQbsA2oA7zsru+glCqbmesOsT/lLP83ogMBfl7RM+5+e5dB1BTo9yiM+gDOJMOmL91/X5vN6qZq3Bsa9nDrrdw6V5UxZjGwuNC25x3eD7nIeTOAGRfZd5UrY1RKuUdaRg7vrtjL5a3CGdLB/Y/feoWzx+H7P0HdTnDVP8E/CJr1h9/egZ4TrM/ucnAVnNgHN0523z3sqsivAEqp8pSTZ+OJuVs4lZnLcyM7Vo2py42BHx6zRmrfNPmPJDHoaWtMRcx0995/w6cQUgc6jXbvfdDEoZRysXyb4fG5m/l51zFeGt2Zjg1reDqk8hEzA3YttFoa9Tv/sb3FQGjS12p15JV8iVunnDwEe5ZArwngV+QIBZfSxKGUchmbzfDMN1tZtPUI/xjRgTsua+bpkMpH6gFY8gw0v8KqbTgSgcFPw6nDsHmme+4fPdX6M/Je91y/EE0cSnmp+BMZzI9JJDffVvzBXsAYw4sLY/l6YyJ/uboNDwxs6emQykd+Hnz7IIgv3PgJ+BTxY7XllVbR+te3IS/HtffPzbKK7+1HQtiFC1i5gyYOpbzQ9sPp3PjR7zw+Zwsj3vuV3/Ye93RIxXpr6R6mrYnjvgEteHyI69bZ8Hq/vQOJG2DkWxf/wS0Cg56B9ATYMsu199/xLWSmQu8HXHvdS9DEoZSXiY5L5bZP1xHo58OrN3UhO8/G+M/W89D0jSSkZhR/AQ/4eNV+Ply5j1t7N+G5kR2qRjEc4PAmWP0qdB4DXW+59LGtr4aGPeHXN63Za11lw2So086qpZQTTRxKeZHVe1IY/9l6IqoH8vXDl3Nrn6YsfXwgT13bjtV7Uhjy9mreXraHzJx8T4d6zvS1cby2ZBejujXklRu7VJ2kkXMWvn0AqtezWhvFEYHBz0BaPGyd45oYEjdCUgz0ecC6fjnRxKGUl1i87Qj3fxFFyzrVmftQPxrVDAYgyN+XP13Zmp+fHMSwzvV5f8Vern5rFYu2HsEY49GYv9mYyD+/38GQDnV5a2w3fH2qSNIAWPpPa9zE6I8huJZz57QZCg26wy9vWrWRstowGQJCodutZb9WCWjiUMoLzI1K4NGvNtGtcU1mTexLneoXPlLZICyY927twdwH+xEWEsCfvtrEbZ+uY9fRUx6IGJZsP8JT87bQv3U4H97e060LM3mdPUsh+jPrCaqWg5w/T8Qa13HyIGz7umwxnD1u1Te63QqB5TvjcBX6L62Ud/rst4P8/Zut9G9dhy/v60NY8KXX4e7TojYL/zyAl0d3ZtfR04x471f+9f120jJc/LTOJazafYw/z4qhR9NaTL4zkiB/90zf7ZUKjw4vqXbDoX4X+OWNsrU6Nn0B+TlWN1U508ShlIcYY3hn2R5eWhjL8M71mTIhkpAA52YB8vURxvdtxqonBzO+bzOmrzvElW+uYub6Q+Tb3Nt9tf7ACR6asZE2dUOZendvqgW6deYi71IwOjwr7fzR4SVR0OpI3W+1GEojP8+adbfFIIhoV7prlIEmDqU8wGYzvLRwJ++t2MstvRrzwW09CPQr+W/tNUMCePGGziz6yxW0rRfKP+ZvZ9SHvxEdl+qGqGFLQhr3fRFNo5rBTHeidVTpxEy3Rodf/fz5o8NLqt1Iq8Wy+nWwleJBhz1LrEd7PdDaAE0cSpW7vHwbT3+zlam/H+Te/i14bUxX/MpYH+jQoAazJ/blw9t7kHo2h5s/Wctjs2M4ku666bx3Hz3NhM83UKuaPzPv70t4EXWYSi31APxoHx3e909lu5aPDwz6uzX1+o75JT9/w2So0RjaDi9bHKVUhdqYSnledl4+f529mR+3H+XxIW35y9WtXfb4qohwXdeGXNW+Lh+v2s+kXw7ww5Yk2tevQe/mtYhsXpvezWtTP6zk3SsHj5/ljinrCfTzYeZ9fUt1jQqtYHS4j9/FR4eXVIdRENHBqnV0usn5a6bshoOrrfqKr2d+hGviUKqcZOTk8eD0jfy69zjPX9eRewe0cMt9QgL8+NvQdoyNbMI3mxKJjjvJ1xsT+WLtIQAa1wqmd/PaRDavRe/mtWkdUR2fSzxGezgtk/FT1mMzhtn396VpeIhb4napsyes+sHRbdCwOzS93KoFlDZJ//a2NTr8pimum9bDxwcGPQXz7oWd30OnG507L2oK+AZY07R7iHj6OfDyEBkZaaKjoz0dhqrC0jNzuXdaFDHxJ3ltTFduiWxS/EkulJdvY+eR00TFpRJ9KJUNB09y/Iw1U2tYsD+RzQpaJLXo0jjsXL0l5XQ2Yyet5fiZbGY90JfOjcLKNe4SycmA3Yutx1z3LQdbnjXGIee0tT+4NjTtC037QbPLoUE38HWiRnN4I0y5xvrBfvNnro3Zlg8f9bVaMg/9XnyrI/s0vNUB2o+wivNuJiIbjTGRhbdri0MpNzt+Jpu7PtvA3mOn+eiOngzr3KDcY/Dz9aFL4zC6NA7j3gEtMMYQn5pBVNxJouNSiYpLZcUua/XmAD8fujUOI7J5bVbuOsbR9Cxm3N/HO5OGLd/qttk6F3b+ADlnILQh9H0Euo6Dep2s2kT8Wji0FuLXWMkFwD8EGkdarZFm/axJCAOqnX/9nLPw7UQIrQ8j33R9/D6+MPDv8O39sOsH6HjDpY/fMttKhH0muj6WEnBri0NEhgHvAb7AFGPMq4X2PwHcD+QBKcC9xphD9n0TgOfsh75sjPnCvr0XMA0Ixlpd8DFTzJfQFofylMNpmdw5ZT1H0rOYdGcvBraN8HRIF3XiTDYbD50k+tBJouJS2ZaYjo+PMHVCbwa0qePp8P5gDBzZbCWL7d9YS7MG1rB+6HYdZ624d6nf3E8nWwkkfh0cWgPJ28HYrNltG3SzWiNN+1mvla9YA/3uWlCygX4lYcuH//UBvyB48NeLx26M1TrxD4YHVpbLFCMXa3G4LXGIiC+wB7gGSASigNuMMbEOx1wJrDfGZIjIw8BgY8w4EakNRAORgAE2Ar2MMSdFZAPwF2A9ViSKGkMAACAASURBVOJ43xjz46Vi0cShPGFHUjoPfBHN6ew8pt3Tm17Nans6pBLJzMkn12ajRpCXPHKbehC2zbPmeTqx1+rnbzMUuo6FNteWflnWrHRIiLKSyaG1VtdUvsOCS/0ehWtfcc13uJgts2H+gzBuJnS4ruhjDv4CX1wPN3wEPe5wbzx2nuiq6gPsM8YcsAcwG7gBOJc4jDErHY5fB4y3v78WWGaMSbWfuwwYJiKrgBrGmHX27V8Co4FLJg6lytOhE2d5e9keFmxJIrxaALMn9qVTQy/s5ilGcIAvwXh4RHhBkXvb15Cw3trWrD9c/qjVwnB2jqhLCQqDNkOsF1jrWyTFWInk7PHSjQ4vqc43w+rXrFf7kUW3JjZ8atVpOt/k/niK4c7E0QhIcPicCFx2iePv448EUNS5jeyvxCK2X0BEJgITAZo2bVqSuJUqleRTWby/Yi9zohLw8xUeGtSKhwa2IizES35jr2h2L4E5d1hF7ogOcPW/oMstUNPNDxb4B1k1j2b93HsfR75+cMWT8P0j1uC+doXGZ6Qnwq5FVsL0Dy6/uC7CK4rjIjIeq1vKZZ2IxpjJwGSwuqpcdV2lCkvLyOHj1fv5Yk0cefmG2/o05c9XtaZujSo21sHVfn/PevR13Ayo17lcpw33iK5j4ZfXrVZH22Hnf9/oz606TOR9novPgVOJQ0S+BT4DfjTGOLuO5WHA8VeDxvZtha89BPgHMMgYk+1w7uBC566yb29caPsF11SqPJzNzuPz3w8y6ZcDnMnOY3T3Rjw+pG3FGOfg7Y7vs7qKhrxgTQhYFfj6wxV/gwV/hr3LoO1Qa3tetjWhYdthUMs71nB3dvjjR8DtwF4ReVVEnJlVKwpoIyItRCQAuBVY4HiAiPQAJgGjjDHHHHb9BAwVkVoiUgsYCvxkjDkCnBKRvmINt70L+N7J76CUS2Tn5TPt94MMemMlby7dw2UtwvnxsSt4Z1x3TRqusnkmiA90Ld91Jjyu220Q1tRqdRQ8uBT7PZxN8di8VEVxqsVhjFkOLBeRMOA2+/sE4FNghjHmgnUQjTF5IvIoVhLwBaYaY3aIyItAtDFmAfAGUB342j7tQrwxZpQxJlVEXsJKPgAvFhTKgUf443HcH9HCuCon+TbDdzGHeWf5HhJPZnJZi9pMurM9vZq5oECr/mDLt9blbn0N1Cj/MS8e5esPVzwBC/8K+1dA6yFWUTy8NbS80tPRneN0jUNEwrGeeroTiAFmAgOACZzfrXSOMWYx1iOzjtued3g/5GL3M8ZMBaYWsT0aKMO0lEqVjDGGpbHJvLV0N3uSz9C5UQ1eubELA9vUqTrLpJan/T/D6SMw/HVPR+IZ3e+wVghc9RqE1LGmOhn2qmvmx3IRZ2sc84F2wHTgenuXEcAcEdEBEqrSWrPvOK/9tJstCWm0jKjGR3f0ZHjn+pow3ClmOoSEW336VZFfAFzxOCz6m7VglH81qwvLizjb4ni/0JiLc4oaHKJURWeM4d8/xDJtTRwNwoJ4bUwXxvRsXObpz1Uxzp6AXYutKTX8Ajwdjef0uBN+ecsa1d7rHgiu6emIzuPs/wUdReRc5Pai9SNuikkpj/vw531MWxPH3Zc3Z+WTgxnXu6kmjfKw7Wuw5ZbbyGiv5RcIA5+0pkHx8LxURXH2/4QHjDFpBR+MMScB7ynxK+VCszfE89ayPdzUsxH/ur5j1VpP25OMsbqpGvawJies6iLvhSd2Qr2Ono7kAs4mDl9x6NS1z0NVhduRqrJaHpvM/83fxsC2Ebw2pqvWMsrTkS1W10yP8cUfWxWIQGg9T0dRJGdrHEuwCuGT7J8ftG9TqtLYFH+SR2dtonOjMD6+oyf+2jVVvmJmWDPEdr7Z05GoYjibOJ7GShYP2z8vA6a4JSKlPGDfsTPcOy2KejWCmHp3b6oFesVsPFVHbhZsmwvtr/O6QrC6kLMDAG3Ax/aXUpVK8qksJkzdgJ+P8OW9fahTPdDTIVU9uxdZ05trN1WF4Ow4jjbAf4GOwLmZ24wxLd0Ul1Ll4lRWLhOmbiAtI4fZE/vRLLxa8Scp14uZAWFNoIWbFktSLuVsJ+7nWK2NPOBK4EtghruCUqo8ZOflM/HLaPYdO8Mnd/aiS+OKt2ZGpZCWAPtXWiOmvWh0tLo4Z/8rBRtjVmCtGHjIGPMCMNJ9YSnlXjab4Yk5W1h3IJU3b+nGFW28d0nXSm/LLMBA99s9HYlykrMVwGwR8cGaHfdRrKnMq7svLKXcxxjDiwtjWbTtCP8Y0YHRPYpcC0yVB5vNmgm3xUCvmTJcFc/ZFsdjQAjWWt+9sCY7nOCuoJRyp09WH2DamjjuH9CCBwZqmc6jDv0OJ+OsKTZUhVFsi8M+2G+cMeZJ4Axwj9ujUspNvtmYyGtLdjGqW0P+b0QHT4ejYmZAYBh0uN7TkagSKLbFYYzJx5o+XakKbdXuYzz9zVb6tw7nzVu64eOjo8I9KivdWqSoyxivWEdbOc/ZGkeMiCwAvgbOFmw0xnzrlqiUcrEtCWk8MnMTbeuF8sn4XgT46dM7HrdjPuRlQncdu1HROJs4goATwFUO2wygiUN5vYPHz3LvtCjCqwcw7d7ehAb5ezokBVY3VUQHaNTT05GoEnJ25LjWNVSFdOx0FndNXY8BvrinD3VDg4o9R5WDY7sgMQqGvmJN5qcqFKfa6yLyuYhMLfxy4rxhIrJbRPaJyDNF7B8oIptEJE9EbnbYfqWIbHZ4ZYnIaPu+aSJy0GFf95J8YVV1nMnO495pURw/ncPUu3vTMkKfIPcam2eAjx90HefpSFQpONtVtdDhfRBwI5B0qRPsT2P9D7gGSASiRGSBMSbW4bB44G7gScdz7asNdrdfpzawD1jqcMhTxph5TsauqpiE1Axmro/n6+gE0jJzmTIhku5NdOI8r5GfC1vmWEvDVteBlxWRs11V3zh+FpFZwG/FnNYH2GeMOWA/ZzZwA3AucRhj4uz7bJe4zs3Aj8aYDGdiVVVTvs2wctcxZqw/xOo9KQgwpEM9HhjYkt7Na3s6POVo7zI4e0wnNKzASjt3dBugbjHHNAISHD4nApeV4l63Am8X2vaKiDwPrACeMcZkFz5JRCYCEwGaNm1aituqiuDY6SzmRiUwa0MCh9MyqRsayJ+vasNtfZrQIEwf8fRKMTOgej1ofY2nI1Gl5OzsuKexnqIqcBRrjQ63EpEGQBfgJ4fNz9rvHwBMtsfxYuFzjTGT7fuJjIw0hferissYw7oDqcxYf4ifth8lz2bo3zqc50Z2YEjHeroAkzc7cwz2LIHLHwVfXfOkonK2qyq0FNc+DDRx+NzYvq0kxgLzjTG5DrEcsb/NFpHPKVQfUZVXemYu325KZOb6ePYdO0NYsD8TLm/OHZc11cJ3RbF1Dph8HbtRwTnb4rgR+NkYk27/XBMYbIz57hKnRQFtRKQFVsK4FSjp9Je3YbUwHGNpYIw5Yl8DfTSwvYTXVBXMtsR0Zqw7xIItSWTm5tOtSU3euLkr13drSJC/r6fDU84yxuqmatwHItp6OhpVBs62Ff9ljJlf8MEYkyYi/wIumjiMMXn2mXR/AnyBqcaYHSLyIhBtjFkgIr2B+UAt4HoR+bcxphOAiDTHarGsLnTpmSISAQiwGXjIye+gKpDMnHx+2JrEzHWH2JKYTrC/Lzd0b8j4vs3o3EjXzaiQDm+ElF1w/fuejkSVkbOJo6hO42LPNcYsBhYX2va8w/sorC6sos6NwyqwF95+1YVHq8pif8oZZq6LZ97GBE5l5dG6bnVeuL4jN/VqTA0d8V2xxUwH/xDodKOnI1Fl5GziiBaRt7HGZQD8CdjonpBUVZObb2NZbDIz1h1izf4T+PsK13aqz/i+zbisRW1ERxZXfDkZsP1b6Dgagmp4OhpVRs4mjj8D/wTmYD1dtQwreShVakfSM5m1Pp7ZUQkcO51No5rBPHVtO8ZGNiEiNNDT4amU3VYxu8d4qF3GdUt2/gDZp6DHHa6JTXmUs09VnQUumDJEqZKy2Qy/7jvOjHWHWLEzGQMMbhvBf/s2Y3C7uvjqVOfeY/m/Yfci+O0d6DwGBjwO9TqV7lox06FWC2jW37UxKo9w9qmqZcAtxpg0++dawGxjzLXuDE5VHqlnc/g6OoGvNsRz6EQG4dUCeHBQK27v05QmtUM8HZ4q7FSSNd6i5wSraylqKmz7GtqNgAFPQJPezl8r9SDE/QpXPacTGlYSznZV1SlIGgDGmJMiUtzIcVXB/W/lPib/coDqgX6EBvlRI8if0CA/+8u/0J+O+//Ytif5DDPXHWLhtiPk5Nno07w2T1zTlmGd6xPop4/Seq2YmdZ4iwF/tbqpBjwBGybD+k/gsyHWGuEDnoCWg4tPBltmAQLdSvo0vvJWziYOm4g0NcbEw7lHZXU0diVmjGHmukNEhAbSpVEYp7NyOZ2Vx5H0LPYcs96fzsoj31b8P4PqgX6Mi2zC+L7NaFe/NGNJVbmy5cOmL6ykUFDbCKkNg5+Bfo/Cxmmw5gOYPhoa9oQr/ma1RHyKePjSlm8lodZXQ9gFD0mqCsrZxPEP4DcRWY01fuIK7PNAqcppR9IpktKzeOPmrtwS2aTIY4wxZObm25NILqfsyaQgyZzOyqVmSAAjuzSgWqBOL1Fh7P8Z0hNg6MsX7gusbk0X0ucB2PwV/P4uzLkDItpbLZDOY86fSuTgajiVCENfKr/4lds5WxxfIiKRWMkiBmvgX6Y7A1OetXTHUXwEru5Q76LHiAghAX6EBPhRr4YukFRpRH8O1SKsVsTF+AVC5D3Q405rCdjf3ob5E2Hly9D/MWtKEf8ga6R4cC1oP7L84ldu52xx/H7gMazBepuBvsBazl9KVlUiS2OTiWxem9rVAjwdiipPBUXxy/8Mfk78t/f1g663WC2NvT/BL2/Cor/B6tetVsnOhdDrbivRqErD2WlEHwN6A4eMMVcCPYC0S5+iKqqE1Ax2HT3N0I4Xb22oSipmhlUU7zWhZOf5+EC74XD/cpjwA9TtAD+/DPnZuu5GJeRsx3OWMSZLRBCRQGPMLhFp59bIlMcsjU0G4BpNHFWLLR82fXl+UbykRKwnrloMhMSNkHoAGnR1ZZTKCzibOBLtM+J+BywTkZPAIfeFpTxpWexR2tULpVl4NU+HosrTvhUXL4qXRuNe1ktVOs4WxwtmJXtBRFYCYcASt0WlPObk2Rw2HEzlkcGtPR2KKm8bpxVfFFeKUiwda4wpPM25qkR+3nUMm4GhnbSbqkopKIr3/4tzRXFVpekam+o8S2OPUr9GEF10zYuqpaAo3vMuT0eiKgBNHOqcrNx8ftlznCEd6+pU5lXJuaL4lWWfBVdVCZo41Dm/7ztOZm4+QzvW93QoqjwVFMV73e3pSFQFoYlDnbN0RzKhgX70bRnu6VBUedKiuCohtyYOERkmIrtFZJ+IXLCeh4gMFJFNIpInIjcX2pcvIpvtrwUO21uIyHr7NeeIiFbyXCDfZlixK5nB7esS4Ke/T1QZBUXxHuO1KK6c5rafECLii7XU7HCgI3CbiHQsdFg8cDfwVRGXyDTGdLe/Rjlsfw14xxjTGjgJ3Ofy4KugmPiTHD+To4P+qhotiqtScOevln2AfcaYA8aYHGA2cIPjAcaYOGPMVsDmzAXFqtheBcyzb/oCGO26kKuuZbHJ+PsKg9tFeDoUVV5s+bDxCy2KqxJzZ+JoBCQ4fE60b3NWkIhEi8g6ESlIDuFAmjEmr7hrishE+/nRKSkpJY29SjHGsDQ2mb4tw6kR5O/pcFR52bfCmvJci+KqhLy5M7uZMSYSuB14V0RaleRkY8xkY0ykMSYyIkJ/i76U/SlnOHj8rE5qWNVs/Byq1dUpz1WJuTNxHAYcVwBqbN/mFGPMYfufB4BVWDPyngBqikjBiPcSXVMVrWBSwyGaOKqOc0XxO8BXW5mqZNyZOKKANvanoAKAW4EFxZwDgIjUEpFA+/s6QH8g1hhjgJVAwRNYE4DvXR55FbN0RzJdG4fRICzY06Go8rJpOhibFsVVqbgtcdjrEI8CPwE7gbnGmB0i8qKIjAIQkd4ikgjcAkwSkR320zsA0SKyBStRvGqMibXvexp4QkT2YdU8PnPXd6gKjp3KYnNCGtdcYqU/VcnoSHFVRm5dCNoYsxhYXGjb8w7vo7C6mwqftwbocpFrHsB6YqvSSzyZwanMPDo2rOG2eyzfeQyAoZ10tHiVsW+5VRS/9hVPR6IqKG8ujldpZ7LzGDdpHWMnreX4mWy33Wdp7FGa1g6hbb3qbruH8jIbp2lRXJWJJg4v9dqPu0hKzyQzN5/3V+x1yz3OZOexZt8Jhnasp5MaVhVaFFcuoInDC607cILp6w5xb/8W3Nq7CV+tj+dAyhmX32f17hRy8m06WrwqOVcUL+Ga4ko50MThZTJz8nn6m600Cw/hyaHt+OuQtgT6+fD6kt0uv9ey2KPUCvGnV7NaLr+28kLnFcVbeDoaVYFp4vAyby3dzaETGbx6U1eCA3yJCA3kwUGtWLLjKNFxqS67T26+jZ93HePqDvXw89V/BlVCQVFcR4qrMtKfGF5kU/xJPvv9IOP7NqVfqz+mNr//ihbUDQ3kP4t3Yg1lKbsNB1M5lZWn3VRViRbFlYto4vASWbn5/H3eVhqGBfPM8A7n7QsJ8ONvQ9uyKT6NH7cfdcn9lsUmE+Tvw8A2Oh1LlZB+WIviymU0cXiJD37ey75jZ/jPTV2oHnjh8JqbezWhXb1QXluyi5w8pyYTvihjDEt3HGVA6wiCA3zLdC1VQcTM0KK4chlNHF5g++F0Pll9gFt6NWZQ26JbAL4+wjMj2nPoRAYz1x8q0/12JJ0iKT1LJzWsKrQorlxME4eH5ebbeGreVsKrBfDcyMLrXJ1vcNsI+rcO5/0Ve0nPzC31PZfFJuMjcHWHuqW+hqpACorikfd4OhJVSWji8LBPVu1n55FTvHJjF8JCLt33LCI8O7wDJzNy+WT1/lLfc2lsMr2a1SK8emCpr6EqkGj79Om6prhyEU0cHrQn+TTv/7yXUd0aOv10U+dGYdzYoxFTfztIUlpmie+ZkJrBziOnGNpR56aqEtIPw96frDXFtSiuXEQTh4fk5dt46usthAb586/rL91FVdjfhrbFAG8uLfmgwGX2tTf0MdwKIPUg/P4ebP0a4tdBeiLk5xV/nqNzRXGdPl25jltnx1UXN/X3g2xJTOeD23qUuMuoca0Q7unfnMm/HOC+AS3o1DDM6XOXxSbTpm51mtepVtKQVXmy2eCb++DwxvO3iy/UaARhjaFmE+vPsCb2l31bgP2/rRbFlZto4vCAAylneGvpHoZ2rMd1XRuU6hqPDG7N3KgE/rt4F9Pv6+PUJIVpGTlsiEvloUG6BoPXi5luJY3r34Om/SAtAdILXonW50Nr4dRhMPnnnxtcy0okQWFWUXzYfzzzHVSlpYmjnNlshqe/2Uqgnw8vj+5c6llpw4L9+fNVbXhxYSyr96QwuF3xT0j9vOsY+TbDNVrf8G4ZqbD8BSth9JwAIhDRruhjbflw+sgfyaRwcmnSV4viyuU0cZSz6esOERV3kjdv6UbdGkFlutb4vs34Ym0c/128iyvaRODrc+kktCw2mXo1AunayPmuLeUBP78EWekw4k0raVyKj6+9u6oxNO1bPvGpKs+txXERGSYiu0Vkn4g8U8T+gSKySUTyRORmh+3dRWStiOwQka0iMs5h3zQROSgim+2v7u78Dq6UkJrBa0t2MahtBGN6Nirz9QL8fPj7te3ZnXyabzYmXvLYrNx8Vu9JYUiHevgUk2CUBx3eZD0+22ci1O/s6WiUKpLbEoeI+AL/A4YDHYHbRKTw40PxwN3AV4W2ZwB3GWM6AcOAd0WkpsP+p4wx3e2vzW75Aq6weRasehWMwRjDM99uxUeE/9zUxWULJ43oUp8eTWvy1rLdZORc/ImbNfuPk5GTr09TeTObDRY/CdUi4MpnPR2NUhflzhZHH2CfMeaAMSYHmA3c4HiAMSbOGLMVsBXavscYs9f+Pgk4BlSs2fjycuCn/4NV/4XoqcyJSuD3fSd4dkR7GtUMdtltRIT/G9GB5FPZTP3t4EWPWxabTPVAv/Nm3VVepqAgPvQlq7CtlJdyZ+JoBCQ4fE60bysREekDBACOQ6VfsXdhvSMi3jn8ec+PkJkKtVpgljzD/EUL6dcynNt6N3X5rXo3r83QjvX4ZPWBItcnt9kMy2KPMahdBIF+OqmhV3IsiHcdV+zhSnmSVw8AFJEGwHTgHmNMQavkWaA90BuoDTx9kXMniki0iESnpKSUS7zniZkBoQ0x9y0llTDe4m1eH9nEbfWFp4e3JzM3n/eWX7g+eUxCGsfPZOukht6sJAVxpTzMnYnjMNDE4XNj+zaniEgNYBHwD2PMuoLtxpgjxpINfI7VJXYBY8xkY0ykMSYyIqKce7lOJVkTy3W/ne/25nB/xqM08DlJk9VPWP3YbtAqojq392nKVxvi2V9offKlsUfx8xGnHtlVHqAFcVXBuDNxRAFtRKSFiAQAtwILnDnRfvx84EtjzLxC+xrY/xRgNLDdpVG7wpbZYGycaHMzLyyIxadpH2Toy9ZCOmvec9ttHxvShmB/X177cdd525fFJtO3ZThhwTpXkdfRgriqgNyWOIwxecCjwE/ATmCuMWaHiLwoIqMARKS3iCQCtwCTRGSH/fSxwEDg7iIeu50pItuAbUAd4GV3fYdSMQZiZmCaXs5TP58hMzef18Z0xafvQ9BxNKx4CeJ+c8ut61QP5KFBLVkam8yGg9b65PuOneFAylmGdtJuKq90riD+shbEVYXh1gGAxpjFwOJC2553eB+F1YVV+LwZwIyLXPMqF4fpWvHrIHU/S2rfwc/bj/HiDZ1oXbe6tW/UB3B0G8y7Fx78FUJd/8P8vgEtmbEunv8s3sn8Ry4/N6nhkA6aOLzOuYL45dB1rKejUcppXl0cr5BiZpDnF8IT25tza+8m3Nm32R/7gmrAuOmQdcqawK6kM506ITjAlyeGtmVzQhqLth1hWexRujQKo6ELHwFWLnKuIP6GFsRVhaKJw5Wyz2Db/i3zc/rSsVkD/n1DpwsH+tXrBCPfgrhfYZV7Jp8b07Mx7euH8sqincQkpOmgP29UUBC/7EEtiKsKRxOHC52JmYdPXgY/BVzDx+N7XnzMRI87oMed8OtbsOcnl8fh6yM8O6IDR9KzMEbX3vA6jgXxwRfMxKOU19PE4SK5+TYSf57MAdOQv0y4jbqhxUxgOOINqNcFvp0IafEuj2dQ2wgGtY2gVUQ12tcPdfn1VRloQVxVcJo4XOTjeUton7ODjE630rVJreJP8A+GsV9Yq7N9fTfkXTjiu6wm3dmLbx/u77J5sZQLaEFcVQKaOFxg9oZ4/LbNwoYvnYc/6PyJ4a3ghv9Zv30ufc7lcQX5+xIWomM3vMqKF62C+EgdIa4qLk0cZbTxUCovfL+FWwN/R9peA6ElXCSp4yjo+yfYMBm2f+OeIJV3OLwJNk6zCuL1Onk6GqVKTRNHGRxJz+TB6Zu4ofouauefQHqML92Frvk3NLkMFvwFUva4NkhPOrAatsyxBkVWdTYbLPobVK+rBXFV4WniKKWs3HwenL6RrNx8nmu0CULqQJtrS3cxX3+4+XPwC4S5d0HOWdcGW97S4mHOePhyFMyfCN8/6pYaToUS8yUkbYJrdMp0VfFp4igFYwzPfruNbYfT+d8NTQmNWwbdbgW/gNJfNKwRjJkCKbtg4RMV87f03CxY/Tp82Af2Loer/gkD/w6bZ8CXN8DZ4+Ubz56lsPI/kLTZs3+fGamw/N9aEFeVhq45XgpTfj3I/JjDPDm0LYOyl4EtF7rfUfYLt7rK6sZY9V9o1g963V32a5aX3UtgydNwMg463gBDX4Ga9smR67aH7x6BT6+E2+ZAvcILQbpYToa1iNbGz63Pq1+DOu2g6y3Q5Rao1dy99y9MC+KqktEWRwmt3pPCf3/cycguDfjT4FbWuhsNe7ruh+HAp6DllbD473Bki2uu6U6pB+CrcTBrHPgGwJ3fwdgv/0gaAJ3HwD2LrVURP7vGSjLucmQLTBpoFaH7PwZP7oXr3oWQcPj5ZXivG3x2LURNsVoC7qYFcVUJiamIXSIlFBkZaaKjo8t8nYPHz3LDh7/RsGYw3z5yOSHHt8HkwTDybeh9X9kDLXD2OHxyhdX1NXE1BNcs/pzylpMBv70Nv79v1WgGPwN9Hrx0d92pJJh1KxzZCte8CJf/2XW/gdtssPZD67f7ahFw4yfQctD5x6TFw7Z5sHUupOwEHz9ofY3VfdRuuDW2xpVsNphyNZw6DI9GaW1DVTgistEYE3nBdk0czjmdlcuNH63hxJlsFjw6gCa1Q6ynZGJmwN92u/6He/x6mDYC2gyFcTPBx0sah8bAzh+srqD0BOgy1koCNRo4d35OBnz3MMR+B93Hw3VvWw8FlMWpI/DdQ3BgFXS4Hq5/H0JqX/o7JG+HrXOsRHL6CASEWud2HQstBoJPCZbYzcuxkkN6ov2VYL2O74X4tXDjZOimy8GqiudiiUNrHE6w2QyPz9nMweNnmXHfZVbSyM2EbV9Dh1HuaRE0vQyu/Q/8+Hf4+UUY8oLr71FSx/fC4qfgwEqo2wnuXgzN+5fsGgEh1hNkq9vD6lchdT+MmwHV6pQupp0LYYH9qa3r34eedxXfihGB+l2s15B/W+ujbJsLsQtgy1dQvT50udmqhzToZtUnziWERKvl4pgkTh8FCv0CVq2u1V3X/69aEFeVjiYOJ7yzfA/Ld1pra/RrFW5t3LXI+oFS2rEbzugzEY7thN/egTptofvt7rvXpWSfhl/egLUfgX8IDH8dIu8D31L+8/HxsVa7i2hb+qJ5zll7AXwaNOgOYz6DOq1LEYuv1aXVcpC13veen6xfCNZPeX8HjwAADQZJREFUsrq+/IIhL/P8c3wDIKyx9Wp19R/vazaBsCZQoxH4FzNXmVIVmCaOYizaeoQPft534doaMTOgZlNofoX7bi5iTYaYesAaHFirhfW0VXkxxhrNvvQ5qzun+3ir5VPdRWu4dx5jPeE063araD7mM2g3rPjzkjbDN/fDiX3Wb/RX/qNsj0IX8A+GTqOtV0YqxH4PKbuhRsM/kkJYE6uG4i1dh0p5gNY4LiE26RRjPl5Dx4Y1+OqBy/6YJj0tHt7tahWEy2MUcOZJmDLE+vP+FVC7hfvvmZcN3z5g/fBs0A1GvAVNervnXqeSYNZt1hNRlyqa22yw9gNr+d1qEXDTJKseoZRyi4vVONz6a5OIDBOR3SKyT+T/27v/YKnK+47j74+oxCg/hSigNWKMDbYNQkKsMcQZUwJOiiRBiyCCyeS3M7XTTmpr1cT8lXbSziQ1/miiQeVnjD+o1QG0GZN0gkIREEIEpDSC/FIckDLWAN/+8Tw3XZbde3fv7p5d9POa2bnnnvOcPd997jn3u+c55zyPjvkPK2m8pFWSDkmaWrZslqRN+TWrZP5YSS/k9/yuWtT1a0Rwy2PrGHDKSceOrbF6fvpZVNPRKYNg+iI4cjjdlfTmvtZu762DsGB6Shqf+CZ84aetSxqQvtFf/2R6/mPZLZWfNN//CjwwBZbdms5KvvIfThpmbdKyxCGpD3AHMAkYBVwjqbwR+zfAbGBe2bqDgduAjwDjgNskdfVVfifwBeD8/KqhbaNX8fP9GWO4d/aHjx5b48iR9CT0yI+npqqinH5eGnb2tc1pzPIWDDsLpOsZc6+CzU/D5H+GS2+s7w6j3uq6aP7xm4590nzD43DnJbBtRRq3/eoHur9rysxaqpVnHOOAzRGxJSLeAhYAV5YWiIitEbEWOFK27ieBZRGxNyJeB5YBEyUNA/pHxPJIbWz3A1Na9QHO6P8uRg3vf/TMrT9PTVWjW3hRvJpzx6dhZzc/BUtvbv77H9yb/mH/5pep+5MxM5u/je50XTSfei+88ny6aP7IV2DhDBh4Dnzp57XdNWVmLdXKxDECeLnk9215XiPrjsjTPb6npC9KWilp5Z49e2oOuker50LfAfCBTzXvPesxdnbqhv3Zu9LTz81yYDfM+VPY+UI6s/nDqT2v0yqlT5qvmZ8ugH9+We/umjKzpnvb3lUVEfcA90C6ON6UN31zX2r3Hz2j+U8Z12PCt1KT1RNfh8EjUx9Xjdi3PfVku/8VmL6w8fdrhhFj03WMN3bCmX/Q7mjMrEQrzzi2AyUdFnFWntfIutvzdG/es3HrfgKH3mztsxu1OKEPTP0hDP19WDS7sTE89m6B+yamM45rH+6MpNHl1CFOGmYdqJWJYwVwvqRzJZ0MTAMW17juEmCCpEH5ovgEYElE7AD2S7o43011HfBYK4Kv6PkH4T2jYPhFhW2yqr79YPqC9PzCvKt712HfnhfhvivSBfFZi4t9RsTMjlstSxwRcQi4gZQENgCLImK9pNslTQaQ9GFJ24CrgLslrc/r7gW+RUo+K4Db8zyArwI/ADYDLwFPtuozHGX3hjQ2+EXXds7F2YG/B9PmpSamhTPTNYFa7VgL902COJK6DumEZGhmxwU/AFirJTenC9J/+WLv+1VqlbWL0sN6F81Mt6v2lNheXgFzP5s69pu1ON3qa2ZWxp0cNuLwb2HNgtT1dqclDUid6L26MfUnNfSC9OR1Nf/1M5g3DfqdAdc9VuyzKGb2tuDEUYuNS+Dgq+kbfae67G9T8lh6C5z+vpTkym1cCotmpj6vrnsU+p1ZfJxmdtxzT221eP7B1NX2eZe3O5LqTjgBptwFw0enDgB3rjt6+fpHUzciQy+A2f/mpGFmvebE0ZM3dsGmpfDBab3vRrwoJ78bps2Hvv1Tn1YHdqf5q+fBQ9enZyNm/Sucenp74zSz45oTR0/WLoA43P5nN2rVfxhcMx8OvpbOMH75/TTi3rnjYebDHr7UzBrW4V+h2ywiNVOdfTEMOb/d0dRu+Gj4zD2w8NrUMeD7J8FVP/LgQmbWFE4c3dm2Il1wnvy9dkdSv66xt/e8CH/yTehzUrsjMrO3CSeO7jz/QBoq9cJPtzuS3hk7q+cyZmZ18jWO7gweCR/5Uurew8zMAJ9xdO/Sv2h3BGZmHcdnHGZmVhcnDjMzq4sTh5mZ1cWJw8zM6uLEYWZmdXHiMDOzujhxmJlZXZw4zMysLu+IoWMl7QH+u5erDwFebWI4zeb4GuP4GuP4GtPp8Z0TEUPLZ74jEkcjJK2sNOZup3B8jXF8jXF8jen0+KpxU5WZmdXFicPMzOrixNGze9odQA8cX2McX2McX2M6Pb6KfI3DzMzq4jMOMzOrixOHmZnVxYkjkzRR0ouSNku6qcLyvpIW5uXPSnpvgbGdLemnkn4lab2kP69Q5jJJ+yStzq9bi4ovb3+rpBfytldWWC5J3831t1bSmAJju6CkXlZL2i/pxrIyhdafpHsl7Za0rmTeYEnLJG3KPwdVWXdWLrNJUkvGB64S3z9I+nX++z0iaWCVdbvdF1oY3zckbS/5G15RZd1uj/UWxrewJLatklZXWbfl9dewiHjHv4A+wEvASOBkYA0wqqzMV4G78vQ0YGGB8Q0DxuTpfsDGCvFdBjzexjrcCgzpZvkVwJOAgIuBZ9v4t95JerCpbfUHjAfGAOtK5v09cFOevgn4doX1BgNb8s9BeXpQQfFNAE7M09+uFF8t+0IL4/sG8Fc1/P27PdZbFV/Z8u8At7ar/hp9+YwjGQdsjogtEfEWsAC4sqzMlcCcPP0QcLkkFRFcROyIiFV5+g1gAzCiiG030ZXA/ZEsBwZKGtaGOC4HXoqI3vYk0BQR8TNgb9ns0n1sDjClwqqfBJZFxN6IeB1YBkwsIr6IWBoRh/Kvy4Gzmr3dWlWpv1rUcqw3rLv48v+Nq4H5zd5uUZw4khHAyyW/b+PYf8y/K5MPnn3A6YVEVyI3kV0EPFth8R9LWiPpSUkXFhoYBLBU0n9K+mKF5bXUcRGmUf2AbWf9AZwRETvy9E7gjAplOqUeP0c6g6ykp32hlW7ITWn3Vmnq64T6+xiwKyI2VVnezvqriRPHcUTSacBPgBsjYn/Z4lWk5pcPAt8DHi04vEsjYgwwCfiapPEFb79Hkk4GJgM/rrC43fV3lEhtFh15r7ykm4FDwNwqRdq1L9wJnAeMBnaQmoM60TV0f7bR8ceSE0eyHTi75Pez8ryKZSSdCAwAXiskurTNk0hJY25EPFy+PCL2R8SBPP0EcJKkIUXFFxHb88/dwCOkJoFStdRxq00CVkXErvIF7a6/bFdX813+ubtCmbbWo6TZwKeAGTm5HaOGfaElImJXRByOiCPAv1TZbrvr70TgM8DCamXaVX/1cOJIVgDnSzo3fyudBiwuK7MY6LqDZSrw79UOnGbLbaI/BDZExD9WKXNm1zUXSeNIf9tCEpukUyX165omXURdV1ZsMXBdvrvqYmBfSbNMUap+02tn/ZUo3cdmAY9VKLMEmCBpUG6KmZDntZykicDXgckRcbBKmVr2hVbFV3rN7NNVtlvLsd5KnwB+HRHbKi1sZ/3Vpd1X5zvlRbrrZyPpjoub87zbSQcJwLtITRybgeeAkQXGdimp2WItsDq/rgC+DHw5l7kBWE+6S2Q5cEmB8Y3M212TY+iqv9L4BNyR6/cF4EMF/31PJSWCASXz2lZ/pAS2A/gtqZ3986RrZk8Dm4CngMG57IeAH5Ss+7m8H24Gri8wvs2k6wNd+2DXXYbDgSe62xcKiu+BvG+tJSWDYeXx5d+POdaLiC/P/1HXPldStvD6a/TlLkfMzKwubqoyM7O6OHGYmVldnDjMzKwuThxmZlYXJw4zM6uLE4dZh8s99z7e7jjMujhxmJlZXZw4zJpE0rWSnsvjKNwtqY+kA5L+SWkclaclDc1lR0taXjK2xaA8/32SnsqdLa6SdF5++9MkPZTHw5hbVM/MZpU4cZg1gaQPAH8GfDQiRgOHgRmkJ9ZXRsSFwDPAbXmV+4G/jog/Ij3t3DV/LnBHpM4WLyE9fQypR+QbgVGkp4s/2vIPZVbFie0OwOxt4nJgLLAinwycQuqk8Aj/36Hdg8DDkgYAAyPimTx/DvDj3EfRiIh4BCAi3gTI7/dc5P6N8shx7wV+0fqPZXYsJw6z5hAwJyL+5qiZ0i1l5Xrbx8//lkwfxseutZGbqsya42lgqqT3wO/GDz+HdIxNzWWmA7+IiH3A65I+lufPBJ6JNLrjNklT8nv0lfTuQj+FWQ38rcWsCSLiV5L+jjRy2wmkXlG/BvwPMC4v2026DgKp2/S7cmLYAlyf588E7pZ0e36Pqwr8GGY1ce+4Zi0k6UBEnNbuOMyayU1VZmZWF59xmJlZXXzGYWZmdXHiMDOzujhxmJlZXZw4zMysLk4cZmZWl/8DrYAwBQm1NA0AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfb7e9e1",
      "metadata": {
        "id": "dfb7e9e1"
      },
      "outputs": [],
      "source": [
        "prediction = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e435500",
      "metadata": {
        "id": "8e435500"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc67dee",
      "metadata": {
        "id": "9dc67dee"
      },
      "outputs": [],
      "source": [
        "#Convert both into same format\n",
        "yt = []\n",
        "pred = []\n",
        "for i in y_test:\n",
        "    yt.append(np.argmax(i))\n",
        "#     pred.append(np.argmax(j))\n",
        "\n",
        "for i in prediction:\n",
        "    pred.append(np.argmax(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b298756",
      "metadata": {
        "id": "0b298756"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5f5e02a",
      "metadata": {
        "id": "c5f5e02a"
      },
      "outputs": [],
      "source": [
        "print(classification_report(yt, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecdb5f2f",
      "metadata": {
        "id": "ecdb5f2f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4212924a",
      "metadata": {
        "id": "4212924a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40e6f8ce",
      "metadata": {
        "id": "40e6f8ce"
      },
      "outputs": [],
      "source": [
        "|"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
